\relax 
\citation{DBLP:journals/corr/MnihBMGLHSK16,DBLP:journals/corr/HasseltGS15,DRL:HumanLevelControl,DRL:Silver_2016,mnih-atari-2013}
\citation{sutton_barto_98}
\citation{DRL:Silver_2016}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Reinforcement Learning (RL)}{1}}
\citation{bottou-bousquet-2008}
\citation{bottou-2010}
\citation{ng_2017}
\citation{ng_2017}
\citation{DBLP:journals/corr/MnihBMGLHSK16,DBLP:journals/corr/HasseltGS15,DRL:HumanLevelControl}
\citation{DRL:HumanLevelControl}
\citation{KarpathyCNN}
\citation{DRL:HumanLevelControl}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Q-learning}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Loss (or Objective) Functions}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Batch vs. Stochastic Gradient Decent}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Contour plots of cost function $J(\theta )$ with marked batch (left) and stochastic gradient descent (right) \cite  {ng_2017}.}}{2}}
\newlabel{fig:gradient_plots}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Artificial Neural Networks (ANN's)}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Convolutional Neural Networks (CNN's)}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-A}0a}The Input layer}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-A}0b}The convolution layer}{2}}
\citation{DBLP:journals/corr/MnihBMGLHSK16}
\citation{DBLP:journals/corr/HasseltGS15}
\citation{DRL:HumanLevelControl}
\citation{DRL:Silver_2016}
\citation{mnih-atari-2013}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Schematic illustration of the convolutional neural network \cite  {DRL:HumanLevelControl}.}}{3}}
\newlabel{fig:conv_net}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Recurrent Neural Networks (RNN's)}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Successful case studies using ANN's for RL}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Asynchronous Methods for Deep Reinforcement Learning}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Deep Reinforcement Learning with Double Q-Learning}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Human-level controll through deep reinforcement learning}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Mastering the game of Go with deep neural networks and tree search}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-E}}Playing Atari with Deep Reinforcement Learning}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Deep Reinforcement Learning}{3}}
\bibstyle{IEEEtran}
\bibdata{paper}
\bibcite{DBLP:journals/corr/MnihBMGLHSK16}{1}
\bibcite{DBLP:journals/corr/HasseltGS15}{2}
\bibcite{DRL:HumanLevelControl}{3}
\bibcite{DRL:Silver_2016}{4}
\bibcite{mnih-atari-2013}{5}
\bibcite{sutton_barto_98}{6}
\bibcite{bottou-bousquet-2008}{7}
\bibcite{bottou-2010}{8}
\bibcite{ng_2017}{9}
\bibcite{KarpathyCNN}{10}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Deep Q-network}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Discussion \& Conclusion}{4}}
\@writefile{toc}{\contentsline {section}{References}{4}}
