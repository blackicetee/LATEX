\relax 
\citation{sutton_barto_98}
\citation{DBLP:journals/corr/MnihBMGLHSK16,DBLP:journals/corr/HasseltGS15,DRL:HumanLevelControl,DRL:Silver_2016,mnih-atari-2013}
\citation{sutton_barto_98}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Agent-environment interaction \cite  {sutton_barto_98}.}}{1}}
\newlabel{fig:agent_environment}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Reinforcement Learning (RL)}{1}}
\citation{ertel_2009}
\citation{DRL:Silver_2016}
\citation{Watkins_1992}
\citation{sutton_barto_98}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Q-learning}{2}}
\newlabel{equ:one step Q function}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Loss Function}{2}}
\citation{bottou-bousquet-2008}
\citation{bottou-2010}
\citation{ng_2017}
\citation{ng_2017}
\citation{ng_2017}
\citation{ng_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Fitting a linear hypothesis with linear regression.}}{3}}
\newlabel{fig:linear_regression_model_fit}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Batch vs. Stochastic Gradient Decent}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Contour plots of cost function $J(\theta )$ with marked batch (left) and stochastic gradient descent (right) \cite  {ng_2017}.}}{3}}
\newlabel{fig:gradient_plots}{{3}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Stochastic gradient descent \cite  {ng_2017}}}{3}}
\newlabel{alg:stochastic gradient descent}{{1}{3}}
\citation{DRL:HumanLevelControl}
\citation{mnih-atari-2013}
\citation{KarpathyCNN}
\citation{DBLP:journals/corr/MnihBMGLHSK16,DBLP:journals/corr/HasseltGS15,DRL:HumanLevelControl}
\citation{DRL:HumanLevelControl}
\citation{KarpathyCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Schematic illustration of the convolutional neural network \cite  {DRL:HumanLevelControl}.}}{4}}
\newlabel{fig:conv_net}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Convolutional Neural Network (CNN/ConvNet)}{4}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-}0a}The Input layer}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Computation inside a convolution layer \cite  {KarpathyCNN}.}}{4}}
\newlabel{fig:convolutional_layer}{{5}{4}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-}0b}The convolution layer}{4}}
\citation{KarpathyCNN}
\citation{mnih-atari-2013}
\citation{mnih-atari-2013}
\citation{mnih-atari-2013}
\citation{sutton_barto_98}
\citation{Watkins_1992}
\citation{mnih-atari-2013}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The pooling layer \cite  {KarpathyCNN}.}}{5}}
\newlabel{fig:pooling_layer}{{6}{5}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-}0c}The rectified linear unit layer}{5}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-}0d}The pooling layer}{5}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-}0e}The output layer}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Playing Atari with Deep Reinforcement Learning}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Deep Reinforcement Learning}{5}}
\newlabel{equ:loss functions}{{2}{5}}
\newlabel{equ:gradient loss}{{3}{5}}
\newlabel{equ:true Q-value-function}{{4}{5}}
\citation{mnih-atari-2013}
\citation{DBLP:journals/corr/HasseltGS15}
\citation{mnih-atari-2013}
\citation{DRL:HumanLevelControl}
\citation{DBLP:journals/corr/MnihBMGLHSK16}
\citation{DRL:Silver_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces DQN results in Atari 2600 emulator \cite  {mnih-atari-2013}.}}{6}}
\newlabel{fig:result_table_dqn}{{7}{6}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Deep Q-learning with Experience Replay \cite  {mnih-atari-2013}}}{6}}
\newlabel{alg:deep q learning}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Experiment results}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Discussion \& Conclusion}{6}}
\citation{mnih-atari-2013}
\bibstyle{IEEEtran}
\bibdata{paper}
\bibcite{sutton_barto_98}{1}
\bibcite{DBLP:journals/corr/MnihBMGLHSK16}{2}
\bibcite{DBLP:journals/corr/HasseltGS15}{3}
\bibcite{DRL:HumanLevelControl}{4}
\bibcite{DRL:Silver_2016}{5}
\bibcite{mnih-atari-2013}{6}
\bibcite{ertel_2009}{7}
\bibcite{Watkins_1992}{8}
\bibcite{bottou-bousquet-2008}{9}
\bibcite{bottou-2010}{10}
\bibcite{ng_2017}{11}
\bibcite{KarpathyCNN}{12}
\@writefile{toc}{\contentsline {section}{References}{7}}
