\chapter{Projektvision}
\label{cha:projektvision}

\section{Motivation}

\section{Zielsetzung}

\section{Realisierung}

\section{Ergebnisse}

\section{Aufbau der Arbeit}


%Zielsetzung
Das Ziel der Arbeit ist es, ein bereits existierendes Lernverfahren zu implementieren und dessen Leistungsfähigkeit und Grenzen zu untersuchen. Das Lernverfahren soll eigenständig und automatisch eine Strategie lernen. Jeweils eine Strategie für das Strategiespiele Tic Tac Toe und das Strategiespiel Reversi. \\  

%Validierung
Die Leistungsfähigkeit und Grenzen beurteilen wir anhand diverser Testspiele. Bei diesen Testspielen spielt die gelernte Strategie gegen die festgelegte Strategie, in den Strategiespielen Tic Tac Toe und Reversi. Wir unterteilen die Testspiele in drei Phasen. In jeder dieser Phasen testen wir ein Stadium der gelernten Strategie. In Phase 1 lernt das Lernverfahren in 1.000 Spielen gegen sich selbst eine Strategie. Wir erhören die Anzahl der Spiele gegen sich selbst in Phase 2 auf 100.000 Spiele und in Phase 3 auf 1.000.000 Spiele gegen sich selbst. Nach Abschluss der Lernphase wird die gelernte Strategie in genau 100 Testspielen gegen eine feste Strategie spielen. \\

%Realisierung nicht lernender Agent / feste Strategie
Die feste Strategie ist eine Kombination aus einem vorausschauenden Suchbaumverfahren und einer Bewertungsfunktion (Heuristik). Ein Suchverfahren für Strategiespiele, durchsucht einen Spielbaum nach der bestmöglichen Aktion (einem Spielzug) in einem gegebenen Zustand. Ein Zustand oder Spielzustand ist eine Spielsituation bzw. eine Stellung der Spielfiguren auf dem Spielfeld. \\

Das Problem der Suchverfahren ist die Dimensionalität bzw. Komplexität des Ausgangsproblems. Suchbaumverfahren können für sehr einfache Probleme relativ schnell eine optimale Aktion finden. Die Größe des Suchbaums wächst exponentiell mit der Komplexität des Problems, d.h. die Laufzeit des Suchbaumverfahrens ohne Erweiterungen könnte für das Strategiespiele Tic Tac Toe nicht handhabbar sein und ist für das Strategiespiel Reversi nicht handhabbar. Wir schreiben ''könnte'' bei Tic Tac Toe, weil dieses noch ein recht einfacher Vertreter der Strategiespiele ist, dahingegen ist Reversi ein komplexeres Strategiespiel. \\

Um die Diemensionalitätsproblematik zu lösen, kombinieren wir Suchbaumverfahren mit Heuristiken, wir bezeichnen diese Kombination als heuristische Suche. Eine Heuristik berechnet eine Gewinnwahrscheinlichkeit, ausgehend von einem Spielzustand. Ein Spielzustand mit einer hohen heuristischen Bewertung ist, gegenüber einem Spielzustand mit niedriger heuristischer Bewertung, zu bevorzugen. \\

Das Suchbaumverfahren muss den Suchbaum, unter Verwendung einer Heuristik, nicht mehr komplett durchsuchen. Die Suche kann in einer bestimmten Suchbaumtiefe abgebrochen werden. Das Suchbaumverfahren liefert die erste Aktion einer Aktionssequenz. Eine Aktionssequenz ist eine Folge von Aktionen und beschreibt einen Pfad im Suchbaum. Die Aktionssequenz, welche von der heuristischen Suche ausgewählt wurde, repräsentiert den Spielzustand mit der maximalen Gewinnwahrscheinlichkeit. \\

Die Qualität dieser Gewinnschätzung ist wiederum von der maximalen Suchtiefe und der Bewertungsfunktion abhängig. Eine größere Suchtiefe resultiert in einer besseren Schätzung, weil unter Umständen mehr Spielzustände berücksichtigt werden können. Die Verwendung einer Bewertungsfunktion ist keine Garantie für eine optimale Strategie. Verschiedene Bewertungsfunktionen können stark voneinander abweichende Gewinnschätzungen für Spielzustände berechnen. \\

Ein weiteres Ziel in dieser Arbeit, ist die Entwicklung einer Bewertungsfunktion für Reversi und Tic Tac Toe. Die Bewertungsfunktion soll ungefähr die spielerische Leistung eines fortgeschrittenen menschlichen Spielers erbringen. Wir testen die Leistungsfähigkeit der Bewertungsfunktionen, genau wie bei der gelernten Strategie, anhand von Testspielen. Die mit der Bewertungsfunktion und dem Suchverfahren ausgestattete feste Strategie, wird gegen eine Zufallsstrategie antreten. 

%Realisierung lernender Agent / gelernte Strategie


%Ergebnisse????????????



