\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\select@language {german}
\contentsline {chapter}{\nonumberline Abk\IeC {\"u}rzungsverzeichnis}{iii}{chapter*.2}
\contentsline {chapter}{\nonumberline Abbildungsverzeichnis}{iv}{chapter*.3}
\contentsline {chapter}{\nonumberline Tabellenverzeichnis}{v}{chapter*.4}
\contentsline {chapter}{\numberline {1}Projektvision}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Zielsetzung}{1}{section.1.2}
\contentsline {section}{\numberline {1.3}Realisierung}{1}{section.1.3}
\contentsline {section}{\numberline {1.4}Ergebnisse}{1}{section.1.4}
\contentsline {section}{\numberline {1.5}Aufbau der Arbeit}{1}{section.1.5}
\contentsline {chapter}{\numberline {2}Strategiespiele und Spieltheorie}{4}{chapter.2}
\contentsline {section}{\numberline {2.1}Das Strategiespiel Tic Tac Toe}{4}{section.2.1}
\contentsline {paragraph}{\nonumberline Spielz\IeC {\"u}ge}{5}{section*.6}
\contentsline {paragraph}{\nonumberline Ziel des Spiels}{5}{section*.7}
\contentsline {section}{\numberline {2.2}Das Strategiespiel Reversi}{6}{section.2.2}
\contentsline {paragraph}{\nonumberline Spielz\IeC {\"u}ge}{7}{section*.8}
\contentsline {paragraph}{\nonumberline Ziel des Spiels}{8}{section*.9}
\contentsline {section}{\numberline {2.3}Spieltheorie}{8}{section.2.3}
\contentsline {paragraph}{\nonumberline Nullsummenspiele}{8}{section*.10}
\contentsline {subsection}{\numberline {2.3.1}Minimax}{9}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Alpha-Beta-K\IeC {\"u}rzung}{10}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Iterativ vertiefende Tiefensuche}{12}{subsection.2.3.3}
\contentsline {paragraph}{\nonumberline Die Breitensuche}{12}{section*.11}
\contentsline {paragraph}{\nonumberline Die Tiefensuche}{13}{section*.12}
\contentsline {paragraph}{\nonumberline Anwendung}{13}{section*.13}
\contentsline {subsection}{\numberline {2.3.4}\IeC {\"U}bergangstabellen}{13}{subsection.2.3.4}
\contentsline {paragraph}{\nonumberline Zobrist Hash}{14}{section*.14}
\contentsline {subsection}{\numberline {2.3.5}Heuristik}{15}{subsection.2.3.5}
\contentsline {chapter}{\numberline {3}Einf\IeC {\"u}hrung in verst\IeC {\"a}rkendes Lernen}{18}{chapter.3}
\contentsline {section}{\numberline {3.1}Verst\IeC {\"a}rkendes Lernen eine Definition}{18}{section.3.1}
\contentsline {section}{\numberline {3.2}Gegen\IeC {\"u}berstellung \IeC {\"u}berwachtes und verst\IeC {\"a}rkendes Lernen}{19}{section.3.2}
\contentsline {section}{\numberline {3.3}Fallbeispiel: Ein Agent im Labyrinth}{21}{section.3.3}
\contentsline {section}{\numberline {3.4}Markov Entscheidungsprozess}{22}{section.3.4}
\contentsline {paragraph}{\nonumberline Ein sequentielles Entscheidungsproblem}{22}{section*.15}
\contentsline {paragraph}{\nonumberline Vollst\IeC {\"a}ndig beobachtbare}{23}{section*.16}
\contentsline {paragraph}{\nonumberline Ein stochastischer \IeC {\"U}bergang}{23}{section*.17}
\contentsline {paragraph}{\nonumberline Das \IeC {\"U}bergangsmodell}{23}{section*.18}
\contentsline {paragraph}{\nonumberline Additive Gewinne}{23}{section*.19}
\contentsline {paragraph}{\nonumberline Anwendung des MEP}{24}{section*.20}
\contentsline {section}{\numberline {3.5}Optimale Taktiken}{24}{section.3.5}
\contentsline {section}{\numberline {3.6}Dynamische Programmierung und Wert-Iteration}{25}{section.3.6}
\contentsline {section}{\numberline {3.7}Temporale Differenz Lernen}{27}{section.3.7}
\contentsline {section}{\numberline {3.8}Q-Lernen}{28}{section.3.8}
\contentsline {chapter}{\numberline {4}Problemanalyse und Anforderungsdefinition}{29}{chapter.4}
\contentsline {section}{\numberline {4.1}Die Problematik}{29}{section.4.1}
\contentsline {paragraph}{\nonumberline Die Spieltheorie}{29}{section*.21}
\contentsline {paragraph}{\nonumberline Die drei Agenten}{31}{section*.22}
\contentsline {section}{\numberline {4.2}Anforderungen}{32}{section.4.2}
\contentsline {chapter}{\numberline {5}Modellierung und Entwurf}{35}{chapter.5}
\contentsline {section}{\numberline {5.1}Tic Tac Toe Heuristik}{35}{section.5.1}
\contentsline {paragraph}{\nonumberline Das Spielfeld}{36}{section*.23}
\contentsline {paragraph}{\nonumberline Kontrolliere die Mitte}{37}{section*.24}
\contentsline {paragraph}{\nonumberline Verteidigung ist der beste Angriff}{39}{section*.25}
\contentsline {section}{\numberline {5.2}Reversi Heuristik}{39}{section.5.2}
\contentsline {section}{\numberline {5.3}Die Strategiespielumgebungen Tic Tac Toe und Reversi}{39}{section.5.3}
\contentsline {paragraph}{\nonumberline getPossibleActions()}{39}{section*.26}
\contentsline {section}{\numberline {5.4}Agent des Zufalls}{40}{section.5.4}
\contentsline {paragraph}{\nonumberline getRandomAction(possibleActionList).}{40}{section*.27}
\contentsline {section}{\numberline {5.5}Agent ohne Lernen}{41}{section.5.5}
\contentsline {paragraph}{\nonumberline getStrategicTicTacToeAction(ticTacToeGameState)}{41}{section*.28}
\contentsline {paragraph}{\nonumberline getStrategicReversiAction(reversiGameState)}{41}{section*.29}
\contentsline {paragraph}{\nonumberline Alternative Realisierung}{41}{section*.30}
\contentsline {section}{\numberline {5.6}Agent mit TD-Q-Lernen}{42}{section.5.6}
\contentsline {chapter}{\numberline {6}Algorithmen und Implementierung}{43}{chapter.6}
\contentsline {section}{\numberline {6.1}Tic Tac Toe}{43}{section.6.1}
\contentsline {section}{\numberline {6.2}Reversi}{43}{section.6.2}
\contentsline {section}{\numberline {6.3}Suchbaumverfahren}{43}{section.6.3}
\contentsline {section}{\numberline {6.4}Heuristiken}{43}{section.6.4}
\contentsline {section}{\numberline {6.5}TD-Q-Lernen}{43}{section.6.5}
\contentsline {chapter}{\numberline {7}Validierung}{46}{chapter.7}
\contentsline {section}{\numberline {7.1}Logiktest der Strategiespiele Tic Tac Toe und Reversi}{46}{section.7.1}
\contentsline {section}{\numberline {7.2}Agententest}{46}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Bewertungskriterien}{46}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Persistenz der Agentenerfahrung}{46}{subsection.7.2.2}
\contentsline {chapter}{\numberline {8}Auswertung}{47}{chapter.8}
\contentsline {section}{\numberline {8.1}Konvergenz des TD-Q-Lernens}{47}{section.8.1}
\contentsline {subsection}{\numberline {8.1.1}Generalisierung oder Funktionsann\IeC {\"a}herung}{47}{subsection.8.1.1}
\contentsline {paragraph}{\nonumberline Samuels Dame-Spiel}{47}{section*.31}
\contentsline {paragraph}{\nonumberline Agent mit TD-Lernen}{47}{section*.32}
\contentsline {subsection}{\numberline {8.1.2}Neuronales Lernen}{48}{subsection.8.1.2}
\contentsline {paragraph}{\nonumberline TD-Gammon}{48}{section*.33}
\contentsline {paragraph}{\nonumberline Sind Lernverfahren \IeC {\"u}berhaupt Sinnvoll?}{48}{section*.34}
\contentsline {section}{\numberline {8.2}Gegen\IeC {\"u}berstellung der Lernverfahren}{48}{section.8.2}
\contentsline {paragraph}{\nonumberline \IeC {\"U}berwachtes Lernen}{48}{section*.35}
\contentsline {paragraph}{\nonumberline Wert-Iteration und dynamische Programmierung}{48}{section*.36}
\contentsline {paragraph}{\nonumberline TD-Lernen}{48}{section*.37}
\contentsline {paragraph}{\nonumberline Q-Lernen}{48}{section*.38}
\contentsline {paragraph}{\nonumberline Funktionsann\IeC {\"a}herung}{48}{section*.39}
