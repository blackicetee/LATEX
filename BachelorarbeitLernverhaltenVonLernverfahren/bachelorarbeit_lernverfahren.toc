\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\select@language {german}
\contentsline {chapter}{\nonumberline Abk\IeC {\"u}rzungsverzeichnis}{iii}{chapter*.2}
\contentsline {chapter}{\nonumberline Abbildungsverzeichnis}{iv}{chapter*.3}
\contentsline {chapter}{\nonumberline Tabellenverzeichnis}{v}{chapter*.4}
\contentsline {chapter}{\numberline {1}Projektvision}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Zielsetzung}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Quantifizierung der Ziele}{1}{section.1.2}
\contentsline {section}{\numberline {1.3}Realisierung des Heuristik Agenten}{2}{section.1.3}
\contentsline {section}{\numberline {1.4}Realisierung des TD-Q lernenden Agent}{3}{section.1.4}
\contentsline {section}{\numberline {1.5}Hypothese}{4}{section.1.5}
\contentsline {chapter}{\numberline {2}Strategiespiele und Spieltheorie}{6}{chapter.2}
\contentsline {section}{\numberline {2.1}Das Strategiespiel Tic Tac Toe}{6}{section.2.1}
\contentsline {paragraph}{\nonumberline Spielz\IeC {\"u}ge}{7}{section*.6}
\contentsline {paragraph}{\nonumberline Ziel des Spiels}{7}{section*.7}
\contentsline {section}{\numberline {2.2}Das Strategiespiel Reversi}{8}{section.2.2}
\contentsline {paragraph}{\nonumberline Spielz\IeC {\"u}ge}{9}{section*.8}
\contentsline {paragraph}{\nonumberline Ziel des Spiels}{10}{section*.9}
\contentsline {section}{\numberline {2.3}Spieltheorie}{10}{section.2.3}
\contentsline {paragraph}{\nonumberline Nullsummenspiele}{10}{section*.10}
\contentsline {subsection}{\numberline {2.3.1}Minimax}{11}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Alpha-Beta-K\IeC {\"u}rzung}{12}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Iterativ vertiefende Tiefensuche}{14}{subsection.2.3.3}
\contentsline {paragraph}{\nonumberline Die Breitensuche}{14}{section*.11}
\contentsline {paragraph}{\nonumberline Die Tiefensuche}{15}{section*.12}
\contentsline {paragraph}{\nonumberline Anwendung}{15}{section*.13}
\contentsline {subsection}{\numberline {2.3.4}\IeC {\"U}bergangstabellen}{15}{subsection.2.3.4}
\contentsline {paragraph}{\nonumberline Zobrist Hash}{16}{section*.14}
\contentsline {subsection}{\numberline {2.3.5}Heuristik}{17}{subsection.2.3.5}
\contentsline {paragraph}{\nonumberline Tic Tac Toe Heuristik}{19}{section*.15}
\contentsline {paragraph}{\nonumberline Reversi Heuristik}{19}{section*.16}
\contentsline {chapter}{\numberline {3}Einf\IeC {\"u}hrung in verst\IeC {\"a}rkendes Lernen}{20}{chapter.3}
\contentsline {section}{\numberline {3.1}Verst\IeC {\"a}rkendes Lernen eine Definition}{20}{section.3.1}
\contentsline {section}{\numberline {3.2}Fallbeispiel: Ein Agent im Labyrinth}{21}{section.3.2}
\contentsline {section}{\numberline {3.3}Markov Entscheidungsprozess}{22}{section.3.3}
\contentsline {paragraph}{\nonumberline Ein sequentielles Entscheidungsproblem}{22}{section*.17}
\contentsline {paragraph}{\nonumberline Vollst\IeC {\"a}ndig beobachtbare}{23}{section*.18}
\contentsline {paragraph}{\nonumberline Ein stochastischer \IeC {\"U}bergang}{23}{section*.19}
\contentsline {paragraph}{\nonumberline Das \IeC {\"U}bergangsmodell}{23}{section*.20}
\contentsline {paragraph}{\nonumberline Additive Gewinne}{23}{section*.21}
\contentsline {paragraph}{\nonumberline Anwendung des MEP}{24}{section*.22}
\contentsline {section}{\numberline {3.4}Optimale Taktiken}{25}{section.3.4}
\contentsline {section}{\numberline {3.5}Dynamische Programmierung und Wert-Iteration}{25}{section.3.5}
\contentsline {section}{\numberline {3.6}Temporale Differenz Lernen}{27}{section.3.6}
\contentsline {section}{\numberline {3.7}TD-Q-Lernen}{28}{section.3.7}
\contentsline {chapter}{\numberline {4}Problemanalyse und Anforderungsdefinition}{29}{chapter.4}
\contentsline {section}{\numberline {4.1}Die Problematik}{29}{section.4.1}
\contentsline {paragraph}{\nonumberline Die Spieltheorie}{29}{section*.23}
\contentsline {paragraph}{\nonumberline Die drei Agenten}{31}{section*.24}
\contentsline {section}{\numberline {4.2}Anforderungen}{32}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Tic Tac Toe Spielumgebung}{32}{subsection.4.2.1}
\contentsline {paragraph}{\nonumberline makeMove(position):}{33}{section*.25}
\contentsline {paragraph}{\nonumberline undoMove():}{33}{section*.26}
\contentsline {paragraph}{\nonumberline getPossibleMoves(): return list}{33}{section*.27}
\contentsline {paragraph}{\nonumberline isTerminal: return bool}{33}{section*.28}
\contentsline {paragraph}{\nonumberline getReward: return float}{33}{section*.29}
\contentsline {subsection}{\numberline {4.2.2}Reversi Spielumgebung}{33}{subsection.4.2.2}
\contentsline {paragraph}{\nonumberline makeMove(position):}{33}{section*.30}
\contentsline {paragraph}{\nonumberline undoMove():}{33}{section*.31}
\contentsline {paragraph}{\nonumberline getPossibleMoves(): return list}{33}{section*.32}
\contentsline {paragraph}{\nonumberline isTerminal: return bool}{34}{section*.33}
\contentsline {paragraph}{\nonumberline getReward: return float}{34}{section*.34}
\contentsline {subsection}{\numberline {4.2.3}Agent des Zufalls}{34}{subsection.4.2.3}
\contentsline {paragraph}{\nonumberline suggestRandomTicTacToeAction(ticTacToeState): return tuple}{34}{section*.35}
\contentsline {paragraph}{\nonumberline suggestRandomReversiAction(reversiState): return tuple}{34}{section*.36}
\contentsline {subsection}{\numberline {4.2.4}Tic Tac Toe Heuristik Agent}{34}{subsection.4.2.4}
\contentsline {paragraph}{\nonumberline suggestAction(ticTacToeState): return tuple}{34}{section*.37}
\contentsline {subsection}{\numberline {4.2.5}Reversi Heuristik Agent}{35}{subsection.4.2.5}
\contentsline {paragraph}{\nonumberline suggestAction(reversiState): return tuple}{35}{section*.38}
\contentsline {subsection}{\numberline {4.2.6}Tic Tac Toe TD-Q lernender Agent}{35}{subsection.4.2.6}
\contentsline {paragraph}{\nonumberline learnTicTacToeInXGames(amountOfGames):}{35}{section*.39}
\contentsline {paragraph}{\nonumberline suggestAction(ticTacToeState): return tuple}{35}{section*.40}
\contentsline {subsection}{\numberline {4.2.7}Reversi TD-Q lernender Agent}{36}{subsection.4.2.7}
\contentsline {paragraph}{\nonumberline learnReversiInXGames(amountOfGames):}{36}{section*.41}
\contentsline {paragraph}{\nonumberline suggestAction(reversiState): return tuple}{36}{section*.42}
\contentsline {subsection}{\numberline {4.2.8}Testen der Agenten}{36}{subsection.4.2.8}
\contentsline {chapter}{\numberline {5}Modellierung und Entwurf}{37}{chapter.5}
\contentsline {section}{\numberline {5.1}Tic Tac Toe Heuristik}{37}{section.5.1}
\contentsline {paragraph}{\nonumberline Das Spielfeld}{38}{section*.43}
\contentsline {paragraph}{\nonumberline Kontrolliere die Mitte}{39}{section*.44}
\contentsline {paragraph}{\nonumberline Verteidigung ist der beste Angriff}{41}{section*.45}
\contentsline {section}{\numberline {5.2}Reversi Heuristik}{41}{section.5.2}
\contentsline {section}{\numberline {5.3}Die Strategiespielumgebungen Tic Tac Toe und Reversi}{41}{section.5.3}
\contentsline {paragraph}{\nonumberline getPossibleActions()}{41}{section*.46}
\contentsline {section}{\numberline {5.4}Agent ohne Lernen}{42}{section.5.4}
\contentsline {paragraph}{\nonumberline getStrategicTicTacToeAction(ticTacToeGameState)}{43}{section*.47}
\contentsline {paragraph}{\nonumberline getStrategicReversiAction(reversiGameState)}{43}{section*.48}
\contentsline {paragraph}{\nonumberline Alternative Realisierung}{43}{section*.49}
\contentsline {section}{\numberline {5.5}Agent mit TD-Q-Lernen}{43}{section.5.5}
\contentsline {chapter}{\numberline {6}Algorithmen und Implementierung}{44}{chapter.6}
\contentsline {section}{\numberline {6.1}Tic Tac Toe}{44}{section.6.1}
\contentsline {section}{\numberline {6.2}Reversi}{44}{section.6.2}
\contentsline {section}{\numberline {6.3}Suchbaumverfahren}{44}{section.6.3}
\contentsline {section}{\numberline {6.4}Heuristiken}{44}{section.6.4}
\contentsline {section}{\numberline {6.5}TD-Q-Lernen}{44}{section.6.5}
\contentsline {chapter}{\numberline {7}Validierung}{47}{chapter.7}
\contentsline {section}{\numberline {7.1}Logiktest der Strategiespiele Tic Tac Toe und Reversi}{47}{section.7.1}
\contentsline {section}{\numberline {7.2}Agententest}{47}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Bewertungskriterien}{47}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Persistenz der Agentenerfahrung}{47}{subsection.7.2.2}
\contentsline {chapter}{\numberline {8}Auswertung}{48}{chapter.8}
\contentsline {section}{\numberline {8.1}Konvergenz des TD-Q-Lernens}{48}{section.8.1}
\contentsline {subsection}{\numberline {8.1.1}Generalisierung oder Funktionsann\IeC {\"a}herung}{48}{subsection.8.1.1}
\contentsline {paragraph}{\nonumberline Samuels Dame-Spiel}{48}{section*.50}
\contentsline {paragraph}{\nonumberline Agent mit TD-Lernen}{48}{section*.51}
\contentsline {subsection}{\numberline {8.1.2}Neuronales Lernen}{49}{subsection.8.1.2}
\contentsline {paragraph}{\nonumberline TD-Gammon}{49}{section*.52}
\contentsline {paragraph}{\nonumberline Sind Lernverfahren \IeC {\"u}berhaupt Sinnvoll?}{49}{section*.53}
\contentsline {section}{\numberline {8.2}Gegen\IeC {\"u}berstellung der Lernverfahren}{49}{section.8.2}
\contentsline {paragraph}{\nonumberline \IeC {\"U}berwachtes Lernen}{49}{section*.54}
\contentsline {paragraph}{\nonumberline Wert-Iteration und dynamische Programmierung}{49}{section*.55}
\contentsline {paragraph}{\nonumberline TD-Lernen}{49}{section*.56}
\contentsline {paragraph}{\nonumberline Q-Lernen}{49}{section*.57}
\contentsline {paragraph}{\nonumberline Funktionsann\IeC {\"a}herung}{49}{section*.58}
\contentsline {section}{\numberline {8.3}Gegen\IeC {\"u}berstellung \IeC {\"u}berwachtes und verst\IeC {\"a}rkendes Lernen}{49}{section.8.3}
