\BOOKMARK [0][-]{chapter*.3}{Abk\374rzungsverzeichnis}{}% 1
\BOOKMARK [0][-]{chapter*.4}{Abbildungsverzeichnis}{}% 2
\BOOKMARK [0][-]{chapter*.5}{Tabellenverzeichnis}{}% 3
\BOOKMARK [0][-]{chapter.1}{Projektvision}{}% 4
\BOOKMARK [1][-]{section.1.1}{Motivation}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.2}{Vorl\344ufige Zielsetzung}{chapter.1}% 6
\BOOKMARK [1][-]{section.1.3}{Nutzen/Zweck des Projektes}{chapter.1}% 7
\BOOKMARK [1][-]{section.1.4}{Zielgruppe}{chapter.1}% 8
\BOOKMARK [0][-]{chapter.2}{Grundlagen}{}% 9
\BOOKMARK [1][-]{section.2.1}{Das Strategiespiel Tic Tac Toe}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.2}{Das Strategiespiel Reversi}{chapter.2}% 11
\BOOKMARK [1][-]{section.2.3}{Spiele mit Gegenspieler}{chapter.2}% 12
\BOOKMARK [2][-]{subsection.2.3.1}{Minimax}{section.2.3}% 13
\BOOKMARK [2][-]{subsection.2.3.2}{Alpha-Beta-K\374rzung}{section.2.3}% 14
\BOOKMARK [2][-]{subsection.2.3.3}{Iterativ vertiefende Tiefensuche}{section.2.3}% 15
\BOOKMARK [2][-]{subsection.2.3.4}{\334bergangstabellen}{section.2.3}% 16
\BOOKMARK [2][-]{subsection.2.3.5}{Heuristik}{section.2.3}% 17
\BOOKMARK [1][-]{section.2.4}{Verst\344rkendes Lernen\(Reinforcement Learing\)}{chapter.2}% 18
\BOOKMARK [2][-]{subsection.2.4.1}{\334berwachtes vs. verst\344rkendes Lernen}{section.2.4}% 19
\BOOKMARK [2][-]{subsection.2.4.2}{Fallbeispiel: Ein Agent im Labyrinth}{section.2.4}% 20
\BOOKMARK [2][-]{subsection.2.4.3}{Markov Entscheidungsprozess}{section.2.4}% 21
\BOOKMARK [2][-]{subsection.2.4.4}{Optimale Taktiken}{section.2.4}% 22
\BOOKMARK [2][-]{subsection.2.4.5}{Temporale Differenz Lernen}{section.2.4}% 23
\BOOKMARK [2][-]{subsection.2.4.6}{Q-Lernen}{section.2.4}% 24
\BOOKMARK [0][-]{chapter.3}{Problemanalyse und Anforderungsdefinition}{}% 25
\BOOKMARK [1][-]{section.3.1}{Die Problematik}{chapter.3}% 26
\BOOKMARK [1][-]{section.3.2}{Anforderungen}{chapter.3}% 27
\BOOKMARK [0][-]{chapter.4}{Modellierung und Entwurf}{}% 28
\BOOKMARK [1][-]{section.4.1}{Tic Tac Toe Heuristik}{chapter.4}% 29
\BOOKMARK [1][-]{section.4.2}{Reversi Heuristik}{chapter.4}% 30
\BOOKMARK [1][-]{section.4.3}{Die Strategiespielumgebungen Tic Tac Toe und Reversi}{chapter.4}% 31
\BOOKMARK [1][-]{section.4.4}{Agent des Zufalls}{chapter.4}% 32
\BOOKMARK [1][-]{section.4.5}{Agent ohne Lernen}{chapter.4}% 33
\BOOKMARK [1][-]{section.4.6}{Agent mit TD-Q-Lernen}{chapter.4}% 34
\BOOKMARK [0][-]{chapter.5}{Algorithmen und Implementierung}{}% 35
\BOOKMARK [1][-]{section.5.1}{Tic Tac Toe}{chapter.5}% 36
\BOOKMARK [1][-]{section.5.2}{Reversi}{chapter.5}% 37
\BOOKMARK [1][-]{section.5.3}{Suchbaumverfahren}{chapter.5}% 38
\BOOKMARK [1][-]{section.5.4}{Heuristiken}{chapter.5}% 39
\BOOKMARK [1][-]{section.5.5}{TD-Q-Lernen}{chapter.5}% 40
\BOOKMARK [0][-]{chapter.6}{Validierung}{}% 41
\BOOKMARK [1][-]{section.6.1}{Logiktest der Strategiespiele Tic Tac Toe und Reversi}{chapter.6}% 42
\BOOKMARK [1][-]{section.6.2}{Agententest}{chapter.6}% 43
\BOOKMARK [2][-]{subsection.6.2.1}{Bewertungskriterien}{section.6.2}% 44
\BOOKMARK [2][-]{subsection.6.2.2}{Persistenz der Agentenerfahrung}{section.6.2}% 45
\BOOKMARK [0][-]{chapter.7}{Auswertung}{}% 46
\BOOKMARK [1][-]{section.7.1}{Konvergenz des TD-Q-Lernens}{chapter.7}% 47
\BOOKMARK [2][-]{subsection.7.1.1}{Generalisierung oder Funktionsann\344herung}{section.7.1}% 48
\BOOKMARK [2][-]{subsection.7.1.2}{Neuronales Lernen}{section.7.1}% 49
\BOOKMARK [1][-]{section.7.2}{Gegen\374berstellung der Lernverfahren}{chapter.7}% 50
\BOOKMARK [0][-]{appendix.A}{I am an appendix!}{}% 51
\BOOKMARK [1][-]{section.A.1}{Section in appendix!}{appendix.A}% 52
\BOOKMARK [0][-]{appendix.B}{Another appendix? What the heck?}{}% 53
\BOOKMARK [1][-]{section.B.1}{Section in appendix!}{appendix.B}% 54
