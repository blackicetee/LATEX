\BOOKMARK [0][-]{chapter*.2}{Abbildungsverzeichnis}{}% 1
\BOOKMARK [0][-]{chapter.1}{Projektvision}{}% 2
\BOOKMARK [1][-]{section.1.1}{Zielsetzung}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Quantifizierung der Ziele}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.3}{Aufbau des Projekts}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.4}{Ergebnisse}{chapter.1}% 6
\BOOKMARK [0][-]{chapter.2}{Strategiespiele und Spielregeln}{}% 7
\BOOKMARK [1][-]{section.2.1}{Das Strategiespiel Tic Tac Toe}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.2}{Das Strategiespiel Reversi}{chapter.2}% 9
\BOOKMARK [0][-]{chapter.3}{Realisierung des Heuristik Agenten}{}% 10
\BOOKMARK [1][-]{section.3.1}{Minimax-Suche}{chapter.3}% 11
\BOOKMARK [1][-]{section.3.2}{Alpha-Beta-K\374rzung}{chapter.3}% 12
\BOOKMARK [1][-]{section.3.3}{Iterativ vertiefende Tiefensuche}{chapter.3}% 13
\BOOKMARK [1][-]{section.3.4}{Heuristik}{chapter.3}% 14
\BOOKMARK [2][-]{subsection.3.4.1}{Tic Tac Toe Heuristik}{section.3.4}% 15
\BOOKMARK [2][-]{subsection.3.4.2}{Reversi Heuristik}{section.3.4}% 16
\BOOKMARK [0][-]{chapter.4}{Realisierung des TD-Q-Agenten \(Verst\344rkendes Lernen\)}{}% 17
\BOOKMARK [1][-]{section.4.1}{Markov-Entscheidungsprozess \(MEP\)}{chapter.4}% 18
\BOOKMARK [2][-]{subsection.4.1.1}{Modellierung der Eigenschaften eines MEP auf Tic Tac Toe und Reversi}{section.4.1}% 19
\BOOKMARK [1][-]{section.4.2}{Optimale Taktiken}{chapter.4}% 20
\BOOKMARK [1][-]{section.4.3}{Verst\344rkende Lernverfahren}{chapter.4}% 21
\BOOKMARK [2][-]{subsection.4.3.1}{Dynamische Programmierung und Wert-Iteration}{section.4.3}% 22
\BOOKMARK [2][-]{subsection.4.3.2}{Lernen mit temporaler Differenz \(TD-Lernen\)}{section.4.3}% 23
\BOOKMARK [2][-]{subsection.4.3.3}{Q-Lernen \(TD-Q-Lernen\)}{section.4.3}% 24
\BOOKMARK [0][-]{chapter.5}{Anforderungsdefinition und Modellierung}{}% 25
\BOOKMARK [1][-]{section.5.1}{Funktionale Anforderungen}{chapter.5}% 26
\BOOKMARK [2][-]{subsection.5.1.1}{Tic Tac Toe Spielumgebung}{section.5.1}% 27
\BOOKMARK [2][-]{subsection.5.1.2}{Reversi Spielumgebung}{section.5.1}% 28
\BOOKMARK [2][-]{subsection.5.1.3}{Agent des Zufalls}{section.5.1}% 29
\BOOKMARK [2][-]{subsection.5.1.4}{Tic Tac Toe Heuristik Agent}{section.5.1}% 30
\BOOKMARK [2][-]{subsection.5.1.5}{Reversi Heuristik Agent}{section.5.1}% 31
\BOOKMARK [2][-]{subsection.5.1.6}{Tic Tac Toe TD-Q-Agent}{section.5.1}% 32
\BOOKMARK [2][-]{subsection.5.1.7}{Agententests in 9 Spielfelder Tic Tac Toe}{section.5.1}% 33
\BOOKMARK [2][-]{subsection.5.1.8}{Agententests in 16 Spielfelder Tic Tac Toe}{section.5.1}% 34
\BOOKMARK [1][-]{section.5.2}{Modellierung}{chapter.5}% 35
\BOOKMARK [0][-]{chapter.6}{Algorithmen und Implementierung}{}% 36
\BOOKMARK [1][-]{section.6.1}{Iterative-Alpha-Beta-Suche}{chapter.6}% 37
\BOOKMARK [1][-]{section.6.2}{TD-Q-Lernen}{chapter.6}% 38
\BOOKMARK [0][-]{chapter.7}{Testergebnisse \(Validierung\)}{}% 39
\BOOKMARK [0][-]{chapter.8}{Auswertung}{}% 40
\BOOKMARK [1][-]{section.8.1}{TD-Q-Lernen - Leistung und Grenzen}{chapter.8}% 41
\BOOKMARK [2][-]{subsection.8.1.1}{TD-Q-Lernen Leistungsf\344higkeit \(Konvergenz\)}{section.8.1}% 42
\BOOKMARK [2][-]{subsection.8.1.2}{TD-Q-Lernen Grenzen \(Fluch der Dimensionalit\344t\)}{section.8.1}% 43
\BOOKMARK [1][-]{section.8.2}{L\366sungen f\374r das Dimensionalit\344tsproblem}{chapter.8}% 44
\BOOKMARK [2][-]{subsection.8.2.1}{Samuels-Dame-Spiel}{section.8.2}% 45
\BOOKMARK [2][-]{subsection.8.2.2}{TD-Gammon}{section.8.2}% 46
