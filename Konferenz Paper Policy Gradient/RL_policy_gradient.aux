\relax 
\citation{sutton_barto_12}
\citation{silver_15}
\@writefile{toc}{\contentsline {section}{\numberline {I}Reinforcement Learning (RL)}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Markov-Entscheidungsprozess}{1}}
\citation{silver_15}
\citation{sutton_99}
\citation{silver_15}
\citation{hoever_14}
\citation{goodfellow_16}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Wertefunktionsapproximation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}Strategiefunktionsapproximation}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Policy Gradient}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Gradientenbasierte lokale Optimierung}{2}}
\citation{andrew_ng_17}
\citation{sutton_99}
\citation{silver_15}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Gradienten Abstiegsverfahren nach Andrew Ng \cite  {andrew_ng_17}.}}{3}}
\newlabel{fig:gradient_descent}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Zielfunktionen}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Bedeutung des Policy Gradient}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Monte-Carlo Policy Gradient}{3}}
\citation{silver_15}
\citation{sutton_barto_12}
\citation{silver_15}
\bibcite{sutton_barto_12}{1}
\bibcite{sutton_99}{2}
\bibcite{hoever_14}{3}
\bibcite{silver_15}{4}
\bibcite{andrew_ng_17}{5}
\bibcite{goodfellow_16}{6}
\@writefile{toc}{\contentsline {section}{References}{4}}
